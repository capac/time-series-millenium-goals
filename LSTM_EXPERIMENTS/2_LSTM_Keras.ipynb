{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras import layers, models\n",
    "from keras import callbacks\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Multiple Input Multi-step output\n",
    "\n",
    "- Use Func to split timeseries in to 6 steps in, 6 steps out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/TrainingSet_Cleaned.csv',index_col=0)\n",
    "submission = pd.read_csv('../data/SubmissionRows.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1972</th>\n",
       "      <th>1973</th>\n",
       "      <th>1974</th>\n",
       "      <th>1975</th>\n",
       "      <th>1976</th>\n",
       "      <th>1977</th>\n",
       "      <th>1978</th>\n",
       "      <th>1979</th>\n",
       "      <th>1980</th>\n",
       "      <th>1981</th>\n",
       "      <th>...</th>\n",
       "      <th>1998</th>\n",
       "      <th>1999</th>\n",
       "      <th>2000</th>\n",
       "      <th>2001</th>\n",
       "      <th>2002</th>\n",
       "      <th>2003</th>\n",
       "      <th>2004</th>\n",
       "      <th>2005</th>\n",
       "      <th>2006</th>\n",
       "      <th>2007</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.267007</td>\n",
       "      <td>0.26767</td>\n",
       "      <td>0.268333</td>\n",
       "      <td>0.268997</td>\n",
       "      <td>0.26966</td>\n",
       "      <td>0.270323</td>\n",
       "      <td>0.270986</td>\n",
       "      <td>0.27165</td>\n",
       "      <td>...</td>\n",
       "      <td>0.279609</td>\n",
       "      <td>0.279609</td>\n",
       "      <td>0.279609</td>\n",
       "      <td>0.279609</td>\n",
       "      <td>0.279609</td>\n",
       "      <td>0.279609</td>\n",
       "      <td>0.279609</td>\n",
       "      <td>0.279609</td>\n",
       "      <td>0.279609</td>\n",
       "      <td>0.279609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.800000</td>\n",
       "      <td>75.200000</td>\n",
       "      <td>67.400000</td>\n",
       "      <td>84.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.152000</td>\n",
       "      <td>0.187000</td>\n",
       "      <td>0.221000</td>\n",
       "      <td>0.256000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.395000</td>\n",
       "      <td>0.430000</td>\n",
       "      <td>0.465000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000879</td>\n",
       "      <td>0.001058</td>\n",
       "      <td>0.012241</td>\n",
       "      <td>0.021071</td>\n",
       "      <td>0.019000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>11.600000</td>\n",
       "      <td>11.800000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>13.600000</td>\n",
       "      <td>15.200000</td>\n",
       "      <td>16.800000</td>\n",
       "      <td>18.400000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     1972  1973      1974     1975      1976      1977     1978      1979  \\\n",
       "16    NaN   NaN  0.267007  0.26767  0.268333  0.268997  0.26966  0.270323   \n",
       "243   NaN   NaN       NaN      NaN       NaN       NaN      NaN       NaN   \n",
       "559   NaN   NaN       NaN      NaN       NaN       NaN      NaN       NaN   \n",
       "618   NaN   NaN       NaN      NaN       NaN       NaN      NaN       NaN   \n",
       "660   NaN   NaN       NaN      NaN       NaN       NaN      NaN       NaN   \n",
       "\n",
       "         1980     1981  ...       1998       1999       2000       2001  \\\n",
       "16   0.270986  0.27165  ...   0.279609   0.279609   0.279609   0.279609   \n",
       "243       NaN      NaN  ...        NaN        NaN        NaN        NaN   \n",
       "559       NaN      NaN  ...   0.152000   0.187000   0.221000   0.256000   \n",
       "618       NaN      NaN  ...   0.000034   0.000039   0.000043   0.000047   \n",
       "660       NaN      NaN  ...  11.600000  11.800000  12.000000  13.600000   \n",
       "\n",
       "          2002       2003       2004       2005       2006       2007  \n",
       "16    0.279609   0.279609   0.279609   0.279609   0.279609   0.279609  \n",
       "243        NaN        NaN  52.800000  75.200000  67.400000  84.600000  \n",
       "559   0.291000   0.325000   0.360000   0.395000   0.430000   0.465000  \n",
       "618   0.000046   0.000879   0.001058   0.012241   0.021071   0.019000  \n",
       "660  15.200000  16.800000  18.400000  20.000000  20.000000  20.000000  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a multivariate sequence into samples\n",
    "def split_sequences(sequences, n_steps_in, n_steps_out):\n",
    "\tX, y = list(), list()\n",
    "\tfor i in range(len(sequences)):\n",
    "\t\t# find the end of this pattern\n",
    "\t\tend_ix = i + n_steps_in\n",
    "\t\tout_end_ix = end_ix + n_steps_out\n",
    "\t\t# check if we are beyond the dataset\n",
    "\t\tif out_end_ix > len(sequences):\n",
    "\t\t\tbreak\n",
    "\t\t# gather input and output parts of the pattern: target is the next n_steps_out rows at the end of n_steps_in\n",
    "\t\tseq_x, seq_y = sequences[i:end_ix, :], sequences[end_ix:out_end_ix, :]\n",
    "\t\tX.append(seq_x)\n",
    "\t\ty.append(seq_y)\n",
    "\treturn np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaler:\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Train, Test sets\n",
    "data = train.loc[:,'1980':'2007'].T\n",
    "\n",
    "data = scaler.fit_transform(data)\n",
    "\n",
    "# Back to DF: Consider timeframe 1990 >\n",
    "data = pd.DataFrame(data,index=train.loc[:,'1980':'2007'].columns,columns=train.loc[:,'1980':'2007'].index)\n",
    "\n",
    "### Fill rest of nan values with -1:\n",
    "data = data.fillna(-1)\n",
    "\n",
    "# Back to numpy:\n",
    "data = data.values\n",
    "\n",
    "# Timesteps as input/Output:\n",
    "n_steps_in =5\n",
    "n_steps_out = 5\n",
    "\n",
    "X, y = split_sequences(data,n_steps_in,n_steps_out)\n",
    "\n",
    "n_features = X.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 4068)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X :  (19, 5, 4068)\n",
      "Shape of y :  (19, 5, 4068)\n"
     ]
    }
   ],
   "source": [
    "# Shape of X, y:\n",
    "print('Shape of X : ',X.shape)\n",
    "print('Shape of y : ',y.shape) # 737 rows to predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Network:\n",
    "\n",
    "Multivariate network, multi-output, predict the 2008 for the submission years\n",
    "\n",
    "- Predicts 5 timesteps ahead (years)\n",
    "\n",
    "- Encoder - Decoder LSTM model\n",
    "\n",
    "- Wrapping output into a TimeDistributed layer\n",
    "\n",
    "- 2 Layer, 200 hidden units\n",
    "\n",
    "- Train 1000 Epochs, validation split 20% (training data)\n",
    "\n",
    "- Early stopping round (patience = 50)\n",
    "\n",
    "- Save best model with ModelCheckpoint\n",
    "\n",
    "Goal: To predict 2008 (Target), 2009, 2010, 2011, 2012 (Target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_LSTM(units,epochs,n_steps_in,n_steps_out,n_features,X,y):\n",
    "    # Define model:\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Masking(mask_value=-1,input_shape=(n_steps_in,n_features)))\n",
    "    model.add(layers.LSTM(units, activation='relu',return_sequences=True))\n",
    "    model.add(layers.TimeDistributed(layers.Dense(y.shape[2])))\n",
    "    # compile:\n",
    "    model.compile(optimizer='adam',loss='mse',metrics=['mean_squared_error'])\n",
    "\n",
    "    # Early stopping round, Model Checkpoint\n",
    "    es = callbacks.EarlyStopping(monitor='val_mean_squared_error',mode='min',patience=60,verbose=1)\n",
    "    mc = callbacks.ModelCheckpoint('ts_un.h5',save_best_only=True,monitor='val_mean_squared_error',mode='min',verbose=1)\n",
    "\n",
    "    # Fit:\n",
    "    history = model.fit(X,y,validation_split=0.1,epochs=epochs,shuffle=False,callbacks=[es,mc])\n",
    "    #plot:\n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.plot(history.history['val_loss'],label='val_loss')\n",
    "    plt.plot(history.history['loss'],label='loss')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17 samples, validate on 2 samples\n",
      "Epoch 1/50\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 0.5888 - mean_squared_error: 0.5888 - val_loss: 0.4795 - val_mean_squared_error: 0.4795\n",
      "\n",
      "Epoch 00001: val_mean_squared_error improved from inf to 0.47949, saving model to ts_un.h5\n",
      "Epoch 2/50\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.7203 - mean_squared_error: 0.7203 - val_loss: 0.4532 - val_mean_squared_error: 0.4532\n",
      "\n",
      "Epoch 00002: val_mean_squared_error improved from 0.47949 to 0.45319, saving model to ts_un.h5\n",
      "Epoch 3/50\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6877 - mean_squared_error: 0.6877 - val_loss: 0.4612 - val_mean_squared_error: 0.4612\n",
      "\n",
      "Epoch 00003: val_mean_squared_error did not improve from 0.45319\n",
      "Epoch 4/50\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6192 - mean_squared_error: 0.6192 - val_loss: 0.4425 - val_mean_squared_error: 0.4425\n",
      "\n",
      "Epoch 00004: val_mean_squared_error improved from 0.45319 to 0.44246, saving model to ts_un.h5\n",
      "Epoch 5/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6264 - mean_squared_error: 0.6264 - val_loss: 0.4454 - val_mean_squared_error: 0.4454\n",
      "\n",
      "Epoch 00005: val_mean_squared_error did not improve from 0.44246\n",
      "Epoch 6/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5711 - mean_squared_error: 0.5711 - val_loss: 0.4985 - val_mean_squared_error: 0.4985\n",
      "\n",
      "Epoch 00006: val_mean_squared_error did not improve from 0.44246\n",
      "Epoch 7/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5562 - mean_squared_error: 0.5562 - val_loss: 0.4373 - val_mean_squared_error: 0.4373\n",
      "\n",
      "Epoch 00007: val_mean_squared_error improved from 0.44246 to 0.43727, saving model to ts_un.h5\n",
      "Epoch 8/50\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5457 - mean_squared_error: 0.5457 - val_loss: 0.4309 - val_mean_squared_error: 0.4309\n",
      "\n",
      "Epoch 00008: val_mean_squared_error improved from 0.43727 to 0.43094, saving model to ts_un.h5\n",
      "Epoch 9/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5342 - mean_squared_error: 0.5342 - val_loss: 0.4352 - val_mean_squared_error: 0.4352\n",
      "\n",
      "Epoch 00009: val_mean_squared_error did not improve from 0.43094\n",
      "Epoch 10/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5145 - mean_squared_error: 0.5145 - val_loss: 0.4215 - val_mean_squared_error: 0.4215\n",
      "\n",
      "Epoch 00010: val_mean_squared_error improved from 0.43094 to 0.42146, saving model to ts_un.h5\n",
      "Epoch 11/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4972 - mean_squared_error: 0.4972 - val_loss: 0.4177 - val_mean_squared_error: 0.4177\n",
      "\n",
      "Epoch 00011: val_mean_squared_error improved from 0.42146 to 0.41770, saving model to ts_un.h5\n",
      "Epoch 12/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4856 - mean_squared_error: 0.4856 - val_loss: 0.4172 - val_mean_squared_error: 0.4172\n",
      "\n",
      "Epoch 00012: val_mean_squared_error improved from 0.41770 to 0.41719, saving model to ts_un.h5\n",
      "Epoch 13/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4638 - mean_squared_error: 0.4638 - val_loss: 0.4185 - val_mean_squared_error: 0.4185\n",
      "\n",
      "Epoch 00013: val_mean_squared_error did not improve from 0.41719\n",
      "Epoch 14/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4467 - mean_squared_error: 0.4467 - val_loss: 0.4060 - val_mean_squared_error: 0.4060\n",
      "\n",
      "Epoch 00014: val_mean_squared_error improved from 0.41719 to 0.40605, saving model to ts_un.h5\n",
      "Epoch 15/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4319 - mean_squared_error: 0.4319 - val_loss: 0.3934 - val_mean_squared_error: 0.3934\n",
      "\n",
      "Epoch 00015: val_mean_squared_error improved from 0.40605 to 0.39337, saving model to ts_un.h5\n",
      "Epoch 16/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4114 - mean_squared_error: 0.4114 - val_loss: 0.3826 - val_mean_squared_error: 0.3826\n",
      "\n",
      "Epoch 00016: val_mean_squared_error improved from 0.39337 to 0.38259, saving model to ts_un.h5\n",
      "Epoch 17/50\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3981 - mean_squared_error: 0.3981 - val_loss: 0.3707 - val_mean_squared_error: 0.3707\n",
      "\n",
      "Epoch 00017: val_mean_squared_error improved from 0.38259 to 0.37068, saving model to ts_un.h5\n",
      "Epoch 18/50\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3798 - mean_squared_error: 0.3798 - val_loss: 0.3601 - val_mean_squared_error: 0.3601\n",
      "\n",
      "Epoch 00018: val_mean_squared_error improved from 0.37068 to 0.36014, saving model to ts_un.h5\n",
      "Epoch 19/50\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3667 - mean_squared_error: 0.3667 - val_loss: 0.3542 - val_mean_squared_error: 0.3542\n",
      "\n",
      "Epoch 00019: val_mean_squared_error improved from 0.36014 to 0.35423, saving model to ts_un.h5\n",
      "Epoch 20/50\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3504 - mean_squared_error: 0.3504 - val_loss: 0.3520 - val_mean_squared_error: 0.3520\n",
      "\n",
      "Epoch 00020: val_mean_squared_error improved from 0.35423 to 0.35196, saving model to ts_un.h5\n",
      "Epoch 21/50\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3391 - mean_squared_error: 0.3391 - val_loss: 0.3484 - val_mean_squared_error: 0.3484\n",
      "\n",
      "Epoch 00021: val_mean_squared_error improved from 0.35196 to 0.34836, saving model to ts_un.h5\n",
      "Epoch 22/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3258 - mean_squared_error: 0.3258 - val_loss: 0.3414 - val_mean_squared_error: 0.3414\n",
      "\n",
      "Epoch 00022: val_mean_squared_error improved from 0.34836 to 0.34140, saving model to ts_un.h5\n",
      "Epoch 23/50\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3140 - mean_squared_error: 0.3140 - val_loss: 0.3352 - val_mean_squared_error: 0.3352\n",
      "\n",
      "Epoch 00023: val_mean_squared_error improved from 0.34140 to 0.33517, saving model to ts_un.h5\n",
      "Epoch 24/50\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3018 - mean_squared_error: 0.3018 - val_loss: 0.3290 - val_mean_squared_error: 0.3290\n",
      "\n",
      "Epoch 00024: val_mean_squared_error improved from 0.33517 to 0.32899, saving model to ts_un.h5\n",
      "Epoch 25/50\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2902 - mean_squared_error: 0.2902 - val_loss: 0.3256 - val_mean_squared_error: 0.3256\n",
      "\n",
      "Epoch 00025: val_mean_squared_error improved from 0.32899 to 0.32565, saving model to ts_un.h5\n",
      "Epoch 26/50\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2781 - mean_squared_error: 0.2781 - val_loss: 0.3220 - val_mean_squared_error: 0.3220\n",
      "\n",
      "Epoch 00026: val_mean_squared_error improved from 0.32565 to 0.32202, saving model to ts_un.h5\n",
      "Epoch 27/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2670 - mean_squared_error: 0.2670 - val_loss: 0.3168 - val_mean_squared_error: 0.3168\n",
      "\n",
      "Epoch 00027: val_mean_squared_error improved from 0.32202 to 0.31684, saving model to ts_un.h5\n",
      "Epoch 28/50\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2558 - mean_squared_error: 0.2558 - val_loss: 0.3099 - val_mean_squared_error: 0.3099\n",
      "\n",
      "Epoch 00028: val_mean_squared_error improved from 0.31684 to 0.30991, saving model to ts_un.h5\n",
      "Epoch 29/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2452 - mean_squared_error: 0.2452 - val_loss: 0.3021 - val_mean_squared_error: 0.3021\n",
      "\n",
      "Epoch 00029: val_mean_squared_error improved from 0.30991 to 0.30207, saving model to ts_un.h5\n",
      "Epoch 30/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2339 - mean_squared_error: 0.2339 - val_loss: 0.2936 - val_mean_squared_error: 0.2936\n",
      "\n",
      "Epoch 00030: val_mean_squared_error improved from 0.30207 to 0.29357, saving model to ts_un.h5\n",
      "Epoch 31/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2247 - mean_squared_error: 0.2247 - val_loss: 0.2836 - val_mean_squared_error: 0.2836\n",
      "\n",
      "Epoch 00031: val_mean_squared_error improved from 0.29357 to 0.28361, saving model to ts_un.h5\n",
      "Epoch 32/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2136 - mean_squared_error: 0.2136 - val_loss: 0.2729 - val_mean_squared_error: 0.2729\n",
      "\n",
      "Epoch 00032: val_mean_squared_error improved from 0.28361 to 0.27285, saving model to ts_un.h5\n",
      "Epoch 33/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2043 - mean_squared_error: 0.2043 - val_loss: 0.2622 - val_mean_squared_error: 0.2622\n",
      "\n",
      "Epoch 00033: val_mean_squared_error improved from 0.27285 to 0.26217, saving model to ts_un.h5\n",
      "Epoch 34/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1948 - mean_squared_error: 0.1948 - val_loss: 0.2513 - val_mean_squared_error: 0.2513\n",
      "\n",
      "Epoch 00034: val_mean_squared_error improved from 0.26217 to 0.25133, saving model to ts_un.h5\n",
      "Epoch 35/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1868 - mean_squared_error: 0.1868 - val_loss: 0.2411 - val_mean_squared_error: 0.2411\n",
      "\n",
      "Epoch 00035: val_mean_squared_error improved from 0.25133 to 0.24111, saving model to ts_un.h5\n",
      "Epoch 36/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1792 - mean_squared_error: 0.1792 - val_loss: 0.2318 - val_mean_squared_error: 0.2318\n",
      "\n",
      "Epoch 00036: val_mean_squared_error improved from 0.24111 to 0.23178, saving model to ts_un.h5\n",
      "Epoch 37/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1720 - mean_squared_error: 0.1720 - val_loss: 0.2237 - val_mean_squared_error: 0.2237\n",
      "\n",
      "Epoch 00037: val_mean_squared_error improved from 0.23178 to 0.22371, saving model to ts_un.h5\n",
      "Epoch 38/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1650 - mean_squared_error: 0.1650 - val_loss: 0.2172 - val_mean_squared_error: 0.2172\n",
      "\n",
      "Epoch 00038: val_mean_squared_error improved from 0.22371 to 0.21715, saving model to ts_un.h5\n",
      "Epoch 39/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1595 - mean_squared_error: 0.1595 - val_loss: 0.2106 - val_mean_squared_error: 0.2106\n",
      "\n",
      "Epoch 00039: val_mean_squared_error improved from 0.21715 to 0.21062, saving model to ts_un.h5\n",
      "Epoch 40/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1544 - mean_squared_error: 0.1544 - val_loss: 0.2028 - val_mean_squared_error: 0.2028\n",
      "\n",
      "Epoch 00040: val_mean_squared_error improved from 0.21062 to 0.20280, saving model to ts_un.h5\n",
      "Epoch 41/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1487 - mean_squared_error: 0.1487 - val_loss: 0.1945 - val_mean_squared_error: 0.1945\n",
      "\n",
      "Epoch 00041: val_mean_squared_error improved from 0.20280 to 0.19453, saving model to ts_un.h5\n",
      "Epoch 42/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1435 - mean_squared_error: 0.1435 - val_loss: 0.1875 - val_mean_squared_error: 0.1875\n",
      "\n",
      "Epoch 00042: val_mean_squared_error improved from 0.19453 to 0.18754, saving model to ts_un.h5\n",
      "Epoch 43/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1395 - mean_squared_error: 0.1395 - val_loss: 0.1823 - val_mean_squared_error: 0.1823\n",
      "\n",
      "Epoch 00043: val_mean_squared_error improved from 0.18754 to 0.18227, saving model to ts_un.h5\n",
      "Epoch 44/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1358 - mean_squared_error: 0.1358 - val_loss: 0.1779 - val_mean_squared_error: 0.1779\n",
      "\n",
      "Epoch 00044: val_mean_squared_error improved from 0.18227 to 0.17785, saving model to ts_un.h5\n",
      "Epoch 45/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1336 - mean_squared_error: 0.1336 - val_loss: 0.1739 - val_mean_squared_error: 0.1739\n",
      "\n",
      "Epoch 00045: val_mean_squared_error improved from 0.17785 to 0.17393, saving model to ts_un.h5\n",
      "Epoch 46/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1351 - mean_squared_error: 0.1351 - val_loss: 0.1709 - val_mean_squared_error: 0.1709\n",
      "\n",
      "Epoch 00046: val_mean_squared_error improved from 0.17393 to 0.17094, saving model to ts_un.h5\n",
      "Epoch 47/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1367 - mean_squared_error: 0.1367 - val_loss: 0.1689 - val_mean_squared_error: 0.1689\n",
      "\n",
      "Epoch 00047: val_mean_squared_error improved from 0.17094 to 0.16894, saving model to ts_un.h5\n",
      "Epoch 48/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1265 - mean_squared_error: 0.1265 - val_loss: 0.1672 - val_mean_squared_error: 0.1672\n",
      "\n",
      "Epoch 00048: val_mean_squared_error improved from 0.16894 to 0.16721, saving model to ts_un.h5\n",
      "Epoch 49/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1242 - mean_squared_error: 0.1242 - val_loss: 0.1644 - val_mean_squared_error: 0.1644\n",
      "\n",
      "Epoch 00049: val_mean_squared_error improved from 0.16721 to 0.16436, saving model to ts_un.h5\n",
      "Epoch 50/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1262 - mean_squared_error: 0.1262 - val_loss: 0.1602 - val_mean_squared_error: 0.1602\n",
      "\n",
      "Epoch 00050: val_mean_squared_error improved from 0.16436 to 0.16020, saving model to ts_un.h5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = model_LSTM(units=128,epochs=1000,X=X,y=y,n_steps_in=n_steps_in,n_steps_out=n_steps_out,n_features=n_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building model:\n",
    "\n",
    "- Encoder ,Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17 samples, validate on 2 samples\n",
      "Epoch 1/50\n",
      "17/17 [==============================] - 2s 101ms/step - loss: 0.5842 - mean_absolute_error: 0.6512 - val_loss: 0.4532 - val_mean_absolute_error: 0.5363\n",
      "\n",
      "Epoch 00001: val_mean_absolute_error improved from inf to 0.53631, saving model to ts_un.h5\n",
      "Epoch 2/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5904 - mean_absolute_error: 0.6578 - val_loss: 0.4497 - val_mean_absolute_error: 0.5410\n",
      "\n",
      "Epoch 00002: val_mean_absolute_error did not improve from 0.53631\n",
      "Epoch 3/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1.0922 - mean_absolute_error: 0.7983 - val_loss: 0.4437 - val_mean_absolute_error: 0.5378\n",
      "\n",
      "Epoch 00003: val_mean_absolute_error did not improve from 0.53631\n",
      "Epoch 4/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6130 - mean_absolute_error: 0.6545 - val_loss: 0.4386 - val_mean_absolute_error: 0.5347\n",
      "\n",
      "Epoch 00004: val_mean_absolute_error improved from 0.53631 to 0.53467, saving model to ts_un.h5\n",
      "Epoch 5/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.7234 - mean_absolute_error: 0.6882 - val_loss: 0.4279 - val_mean_absolute_error: 0.5316\n",
      "\n",
      "Epoch 00005: val_mean_absolute_error improved from 0.53467 to 0.53162, saving model to ts_un.h5\n",
      "Epoch 6/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6719 - mean_absolute_error: 0.6598 - val_loss: 0.4177 - val_mean_absolute_error: 0.5278\n",
      "\n",
      "Epoch 00006: val_mean_absolute_error improved from 0.53162 to 0.52776, saving model to ts_un.h5\n",
      "Epoch 7/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5751 - mean_absolute_error: 0.6150 - val_loss: 0.4154 - val_mean_absolute_error: 0.5312\n",
      "\n",
      "Epoch 00007: val_mean_absolute_error did not improve from 0.52776\n",
      "Epoch 8/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4874 - mean_absolute_error: 0.5719 - val_loss: 0.4100 - val_mean_absolute_error: 0.5302\n",
      "\n",
      "Epoch 00008: val_mean_absolute_error did not improve from 0.52776\n",
      "Epoch 9/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4631 - mean_absolute_error: 0.5508 - val_loss: 0.3985 - val_mean_absolute_error: 0.5232\n",
      "\n",
      "Epoch 00009: val_mean_absolute_error improved from 0.52776 to 0.52318, saving model to ts_un.h5\n",
      "Epoch 10/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4134 - mean_absolute_error: 0.5236 - val_loss: 0.3972 - val_mean_absolute_error: 0.5237\n",
      "\n",
      "Epoch 00010: val_mean_absolute_error did not improve from 0.52318\n",
      "Epoch 11/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3915 - mean_absolute_error: 0.5056 - val_loss: 0.3982 - val_mean_absolute_error: 0.5238\n",
      "\n",
      "Epoch 00011: val_mean_absolute_error did not improve from 0.52318\n",
      "Epoch 12/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3628 - mean_absolute_error: 0.4826 - val_loss: 0.3835 - val_mean_absolute_error: 0.5116\n",
      "\n",
      "Epoch 00012: val_mean_absolute_error improved from 0.52318 to 0.51162, saving model to ts_un.h5\n",
      "Epoch 13/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3342 - mean_absolute_error: 0.4531 - val_loss: 0.3767 - val_mean_absolute_error: 0.5072\n",
      "\n",
      "Epoch 00013: val_mean_absolute_error improved from 0.51162 to 0.50718, saving model to ts_un.h5\n",
      "Epoch 14/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3069 - mean_absolute_error: 0.4338 - val_loss: 0.3700 - val_mean_absolute_error: 0.5029\n",
      "\n",
      "Epoch 00014: val_mean_absolute_error improved from 0.50718 to 0.50294, saving model to ts_un.h5\n",
      "Epoch 15/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.2854 - mean_absolute_error: 0.4129 - val_loss: 0.3639 - val_mean_absolute_error: 0.4982\n",
      "\n",
      "Epoch 00015: val_mean_absolute_error improved from 0.50294 to 0.49818, saving model to ts_un.h5\n",
      "Epoch 16/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2628 - mean_absolute_error: 0.3918 - val_loss: 0.3579 - val_mean_absolute_error: 0.4918\n",
      "\n",
      "Epoch 00016: val_mean_absolute_error improved from 0.49818 to 0.49179, saving model to ts_un.h5\n",
      "Epoch 17/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.2435 - mean_absolute_error: 0.3732 - val_loss: 0.3526 - val_mean_absolute_error: 0.4836\n",
      "\n",
      "Epoch 00017: val_mean_absolute_error improved from 0.49179 to 0.48362, saving model to ts_un.h5\n",
      "Epoch 18/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.2247 - mean_absolute_error: 0.3563 - val_loss: 0.3469 - val_mean_absolute_error: 0.4748\n",
      "\n",
      "Epoch 00018: val_mean_absolute_error improved from 0.48362 to 0.47483, saving model to ts_un.h5\n",
      "Epoch 19/50\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.2063 - mean_absolute_error: 0.3396 - val_loss: 0.3389 - val_mean_absolute_error: 0.4667\n",
      "\n",
      "Epoch 00019: val_mean_absolute_error improved from 0.47483 to 0.46667, saving model to ts_un.h5\n",
      "Epoch 20/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1922 - mean_absolute_error: 0.3247 - val_loss: 0.3299 - val_mean_absolute_error: 0.4595\n",
      "\n",
      "Epoch 00020: val_mean_absolute_error improved from 0.46667 to 0.45947, saving model to ts_un.h5\n",
      "Epoch 21/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1805 - mean_absolute_error: 0.3116 - val_loss: 0.3207 - val_mean_absolute_error: 0.4521\n",
      "\n",
      "Epoch 00021: val_mean_absolute_error improved from 0.45947 to 0.45213, saving model to ts_un.h5\n",
      "Epoch 22/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1704 - mean_absolute_error: 0.3001 - val_loss: 0.3113 - val_mean_absolute_error: 0.4435\n",
      "\n",
      "Epoch 00022: val_mean_absolute_error improved from 0.45213 to 0.44345, saving model to ts_un.h5\n",
      "Epoch 23/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1598 - mean_absolute_error: 0.2887 - val_loss: 0.3013 - val_mean_absolute_error: 0.4328\n",
      "\n",
      "Epoch 00023: val_mean_absolute_error improved from 0.44345 to 0.43282, saving model to ts_un.h5\n",
      "Epoch 24/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1514 - mean_absolute_error: 0.2792 - val_loss: 0.2911 - val_mean_absolute_error: 0.4202\n",
      "\n",
      "Epoch 00024: val_mean_absolute_error improved from 0.43282 to 0.42024, saving model to ts_un.h5\n",
      "Epoch 25/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1458 - mean_absolute_error: 0.2720 - val_loss: 0.2810 - val_mean_absolute_error: 0.4064\n",
      "\n",
      "Epoch 00025: val_mean_absolute_error improved from 0.42024 to 0.40640, saving model to ts_un.h5\n",
      "Epoch 26/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1388 - mean_absolute_error: 0.2615 - val_loss: 0.2707 - val_mean_absolute_error: 0.3923\n",
      "\n",
      "Epoch 00026: val_mean_absolute_error improved from 0.40640 to 0.39228, saving model to ts_un.h5\n",
      "Epoch 27/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1352 - mean_absolute_error: 0.2558 - val_loss: 0.2598 - val_mean_absolute_error: 0.3787\n",
      "\n",
      "Epoch 00027: val_mean_absolute_error improved from 0.39228 to 0.37870, saving model to ts_un.h5\n",
      "Epoch 28/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1303 - mean_absolute_error: 0.2489 - val_loss: 0.2488 - val_mean_absolute_error: 0.3666\n",
      "\n",
      "Epoch 00028: val_mean_absolute_error improved from 0.37870 to 0.36656, saving model to ts_un.h5\n",
      "Epoch 29/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1261 - mean_absolute_error: 0.2435 - val_loss: 0.2383 - val_mean_absolute_error: 0.3561\n",
      "\n",
      "Epoch 00029: val_mean_absolute_error improved from 0.36656 to 0.35614, saving model to ts_un.h5\n",
      "Epoch 30/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1232 - mean_absolute_error: 0.2393 - val_loss: 0.2289 - val_mean_absolute_error: 0.3465\n",
      "\n",
      "Epoch 00030: val_mean_absolute_error improved from 0.35614 to 0.34653, saving model to ts_un.h5\n",
      "Epoch 31/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1209 - mean_absolute_error: 0.2353 - val_loss: 0.2209 - val_mean_absolute_error: 0.3370\n",
      "\n",
      "Epoch 00031: val_mean_absolute_error improved from 0.34653 to 0.33702, saving model to ts_un.h5\n",
      "Epoch 32/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1173 - mean_absolute_error: 0.2300 - val_loss: 0.2139 - val_mean_absolute_error: 0.3277\n",
      "\n",
      "Epoch 00032: val_mean_absolute_error improved from 0.33702 to 0.32773, saving model to ts_un.h5\n",
      "Epoch 33/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1153 - mean_absolute_error: 0.2274 - val_loss: 0.2072 - val_mean_absolute_error: 0.3193\n",
      "\n",
      "Epoch 00033: val_mean_absolute_error improved from 0.32773 to 0.31929, saving model to ts_un.h5\n",
      "Epoch 34/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1136 - mean_absolute_error: 0.2247 - val_loss: 0.2004 - val_mean_absolute_error: 0.3119\n",
      "\n",
      "Epoch 00034: val_mean_absolute_error improved from 0.31929 to 0.31187, saving model to ts_un.h5\n",
      "Epoch 35/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1117 - mean_absolute_error: 0.2218 - val_loss: 0.1941 - val_mean_absolute_error: 0.3055\n",
      "\n",
      "Epoch 00035: val_mean_absolute_error improved from 0.31187 to 0.30552, saving model to ts_un.h5\n",
      "Epoch 36/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1095 - mean_absolute_error: 0.2176 - val_loss: 0.1888 - val_mean_absolute_error: 0.3001\n",
      "\n",
      "Epoch 00036: val_mean_absolute_error improved from 0.30552 to 0.30010, saving model to ts_un.h5\n",
      "Epoch 37/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1081 - mean_absolute_error: 0.2154 - val_loss: 0.1845 - val_mean_absolute_error: 0.2954\n",
      "\n",
      "Epoch 00037: val_mean_absolute_error improved from 0.30010 to 0.29544, saving model to ts_un.h5\n",
      "Epoch 38/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1063 - mean_absolute_error: 0.2121 - val_loss: 0.1810 - val_mean_absolute_error: 0.2912\n",
      "\n",
      "Epoch 00038: val_mean_absolute_error improved from 0.29544 to 0.29123, saving model to ts_un.h5\n",
      "Epoch 39/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1047 - mean_absolute_error: 0.2093 - val_loss: 0.1781 - val_mean_absolute_error: 0.2873\n",
      "\n",
      "Epoch 00039: val_mean_absolute_error improved from 0.29123 to 0.28730, saving model to ts_un.h5\n",
      "Epoch 40/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1035 - mean_absolute_error: 0.2074 - val_loss: 0.1752 - val_mean_absolute_error: 0.2835\n",
      "\n",
      "Epoch 00040: val_mean_absolute_error improved from 0.28730 to 0.28346, saving model to ts_un.h5\n",
      "Epoch 41/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1024 - mean_absolute_error: 0.2054 - val_loss: 0.1724 - val_mean_absolute_error: 0.2799\n",
      "\n",
      "Epoch 00041: val_mean_absolute_error improved from 0.28346 to 0.27994, saving model to ts_un.h5\n",
      "Epoch 42/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1005 - mean_absolute_error: 0.2015 - val_loss: 0.1701 - val_mean_absolute_error: 0.2772\n",
      "\n",
      "Epoch 00042: val_mean_absolute_error improved from 0.27994 to 0.27724, saving model to ts_un.h5\n",
      "Epoch 43/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0991 - mean_absolute_error: 0.1992 - val_loss: 0.1685 - val_mean_absolute_error: 0.2753\n",
      "\n",
      "Epoch 00043: val_mean_absolute_error improved from 0.27724 to 0.27527, saving model to ts_un.h5\n",
      "Epoch 44/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0984 - mean_absolute_error: 0.1986 - val_loss: 0.1676 - val_mean_absolute_error: 0.2732\n",
      "\n",
      "Epoch 00044: val_mean_absolute_error improved from 0.27527 to 0.27321, saving model to ts_un.h5\n",
      "Epoch 45/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0964 - mean_absolute_error: 0.1938 - val_loss: 0.1673 - val_mean_absolute_error: 0.2714\n",
      "\n",
      "Epoch 00045: val_mean_absolute_error improved from 0.27321 to 0.27137, saving model to ts_un.h5\n",
      "Epoch 46/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0953 - mean_absolute_error: 0.1921 - val_loss: 0.1669 - val_mean_absolute_error: 0.2704\n",
      "\n",
      "Epoch 00046: val_mean_absolute_error improved from 0.27137 to 0.27038, saving model to ts_un.h5\n",
      "Epoch 47/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0936 - mean_absolute_error: 0.1896 - val_loss: 0.1662 - val_mean_absolute_error: 0.2697\n",
      "\n",
      "Epoch 00047: val_mean_absolute_error improved from 0.27038 to 0.26968, saving model to ts_un.h5\n",
      "Epoch 48/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0926 - mean_absolute_error: 0.1890 - val_loss: 0.1654 - val_mean_absolute_error: 0.2686\n",
      "\n",
      "Epoch 00048: val_mean_absolute_error improved from 0.26968 to 0.26859, saving model to ts_un.h5\n",
      "Epoch 49/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0912 - mean_absolute_error: 0.1865 - val_loss: 0.1648 - val_mean_absolute_error: 0.2671\n",
      "\n",
      "Epoch 00049: val_mean_absolute_error improved from 0.26859 to 0.26714, saving model to ts_un.h5\n",
      "Epoch 50/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0897 - mean_absolute_error: 0.1839 - val_loss: 0.1643 - val_mean_absolute_error: 0.2656\n",
      "\n",
      "Epoch 00050: val_mean_absolute_error improved from 0.26714 to 0.26564, saving model to ts_un.h5\n"
     ]
    }
   ],
   "source": [
    "# Define model: 128 units\n",
    "model = models.Sequential()\n",
    "model.add(layers.Masking(mask_value=-1,input_shape=(n_steps_in,n_features)))\n",
    "model.add(layers.LSTM(128, activation='relu'))\n",
    "model.add(layers.RepeatVector(n_steps_out))\n",
    "model.add(layers.LSTM(128, activation='relu', return_sequences=True))\n",
    "model.add(layers.TimeDistributed(layers.Dense(y.shape[2])))\n",
    "# compile:\n",
    "model.compile(optimizer='adam',loss='mse',metrics=['mean_absolute_error'])\n",
    "\n",
    "# Early stopping round, Model Checkpoint\n",
    "es = callbacks.EarlyStopping(monitor='val_mean_absolute_error',mode='min',patience=200,verbose=1)\n",
    "mc = callbacks.ModelCheckpoint('ts_un.h5',save_best_only=True,monitor='val_mean_absolute_error',mode='min',verbose=1)\n",
    "\n",
    "# Fit:\n",
    "history = model.fit(X,y,validation_split=0.1,epochs=2000,shuffle=False,callbacks=[es,mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test:\n",
    "X_input = data[-5:,:].reshape(1,5,data.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict: Load Model\n",
    "saved_model = models.load_model('ts_un.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_2008_2012 = saved_model.predict(X_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_2008_2012 = y_pred_2008_2012.reshape(5,y_pred_2008_2012.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build back DF:\n",
    "index_years = list(train.loc[:,'1980':'2007'].columns) + [str(x) for x in range(2008,2013)]\n",
    "columns = list(train.loc[:,'1980':'2007'].index)\n",
    "df_1972_2012 = pd.DataFrame(np.concatenate([data,y_pred_2008_2012]),index=index_years,columns=columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        , -1.        , -1.        , ..., -1.        ,\n",
       "        -1.        , -1.        ],\n",
       "       [ 0.07692308, -1.        , -1.        , ..., -1.        ,\n",
       "        -1.        , -1.        ],\n",
       "       [ 0.15384615, -1.        , -1.        , ..., -1.        ,\n",
       "        -1.        , -1.        ],\n",
       "       ...,\n",
       "       [ 1.03271341, -1.28987098,  1.7063452 , ..., -3.00870514,\n",
       "        -3.69164562, -4.21593857],\n",
       "       [ 0.97096467, -1.48851275,  3.23016381, ..., -3.53954601,\n",
       "        -4.49042654, -4.94068241],\n",
       "       [ 0.96510339, -1.962901  ,  4.73162079, ..., -3.78830433,\n",
       "        -4.87007952, -5.43864202]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1972_2012.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put into right format\n",
    "df_1972_2012_unscaled = scaler.inverse_transform(df_1972_2012.values)\n",
    "\n",
    "df_1972_2012_unscaled = pd.DataFrame(df_1972_2012_unscaled,index=index_years,columns=columns)\n",
    "\n",
    "df_1972_2012_unscaled = df_1972_2012_unscaled.T\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incase values became negative:\n",
    "df_1972_2012_unscaled = df_1972_2012_unscaled[['2008','2012']].applymap(lambda x: abs(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submission columns:\n",
    "df_pred = df_1972_2012_unscaled.loc[submission.index,:]\n",
    "\n",
    "df_pred.columns = submission.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred.to_csv('Final_Pred.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
